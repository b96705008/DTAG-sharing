{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def load_data(files, parts=range(0, 10)+[\"x\"]):\n",
    "    dataset_x, dataset_y = [], []\n",
    "\n",
    "    for part in parts:\n",
    "        for filepath in glob.iglob(files.format(part)):\n",
    "            x = np.load(filepath)\n",
    "\n",
    "            y = [0]*len(parts)\n",
    "            y[parts.index(part)] = 1\n",
    "\n",
    "            dataset_x.append(x)\n",
    "            dataset_y.append(y)\n",
    "\n",
    "    dataset_x = np.array(dataset_x)\n",
    "    dataset_y = np.array(dataset_y)\n",
    "\n",
    "    return dataset_x, dataset_y\n",
    "\n",
    "dataset_x, dataset_y = load_data(os.path.join(\"data\", \"number\", \"{}\", \"*.npy\"))\n",
    "\n",
    "print dataset_x.shape\n",
    "\n",
    "testing_size = 0.33\n",
    "nb_epoch=8\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4217 samples, validate on 2078 samples\n",
      "Epoch 1/8\n",
      "4217/4217 [==============================] - 1s - loss: 1.7763 - acc: 0.4589 - val_loss: 1.1553 - val_acc: 0.6453\n",
      "Epoch 2/8\n",
      "4217/4217 [==============================] - 0s - loss: 1.0517 - acc: 0.6697 - val_loss: 0.9638 - val_acc: 0.7036\n",
      "Epoch 3/8\n",
      "4217/4217 [==============================] - 0s - loss: 0.8661 - acc: 0.7327 - val_loss: 0.9883 - val_acc: 0.6949\n",
      "Epoch 4/8\n",
      "4217/4217 [==============================] - 0s - loss: 0.7686 - acc: 0.7641 - val_loss: 0.9200 - val_acc: 0.7300\n",
      "Epoch 5/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.6896 - acc: 0.7951 - val_loss: 0.8578 - val_acc: 0.7459\n",
      "Epoch 6/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.6125 - acc: 0.8224 - val_loss: 0.6207 - val_acc: 0.8268\n",
      "Epoch 7/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.5322 - acc: 0.8449 - val_loss: 0.6556 - val_acc: 0.8037\n",
      "Epoch 8/8\n",
      "4217/4217 [==============================] - 0s - loss: 0.4713 - acc: 0.8693 - val_loss: 0.5949 - val_acc: 0.8272\n",
      "Baseline Error of Validation Set: 17.27622711%\n"
     ]
    }
   ],
   "source": [
    "mlp_preprocess = lambda dataset: dataset.reshape(dataset.shape[0], dataset.shape[1]*dataset.shape[2]).astype('float32') / 255\n",
    "\n",
    "dataset = mlp_preprocess(dataset_x)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(dataset.shape[1], input_dim=dataset.shape[1], init='normal', activation='relu'))\n",
    "model.add(Dense(dataset_y.shape[1], init='normal', activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(dataset, dataset_y, test_size=testing_size)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "scores = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "print \"Baseline Error of Validation Set: {:.8f}%\".format(100-scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6295, 32, 26, 1) 32 26 (6295, 11)\n",
      "Train on 4217 samples, validate on 2078 samples\n",
      "Epoch 1/8\n",
      "4217/4217 [==============================] - 3s - loss: 1.5003 - acc: 0.5478 - val_loss: 0.8654 - val_acc: 0.7642\n",
      "Epoch 2/8\n",
      "4217/4217 [==============================] - 3s - loss: 0.6666 - acc: 0.8165 - val_loss: 0.6290 - val_acc: 0.8272\n",
      "Epoch 3/8\n",
      "4217/4217 [==============================] - 2s - loss: 0.4382 - acc: 0.8848 - val_loss: 0.4857 - val_acc: 0.8739\n",
      "Epoch 4/8\n",
      "4217/4217 [==============================] - 3s - loss: 0.3160 - acc: 0.9115 - val_loss: 0.4007 - val_acc: 0.8956\n",
      "Epoch 5/8\n",
      "4217/4217 [==============================] - 3s - loss: 0.2427 - acc: 0.9334 - val_loss: 0.3593 - val_acc: 0.9047\n",
      "Epoch 6/8\n",
      "4217/4217 [==============================] - 3s - loss: 0.1822 - acc: 0.9542 - val_loss: 0.3675 - val_acc: 0.9028\n",
      "Epoch 7/8\n",
      "4217/4217 [==============================] - 4s - loss: 0.1544 - acc: 0.9583 - val_loss: 0.3206 - val_acc: 0.9192\n",
      "Epoch 8/8\n",
      "4217/4217 [==============================] - 3s - loss: 0.1191 - acc: 0.9699 - val_loss: 0.2860 - val_acc: 0.9302\n",
      "Baseline Error of Validation Set: 6.97786336%\n"
     ]
    }
   ],
   "source": [
    "def cnn_preprocess(dataset):\n",
    "    h, w = dataset.shape[1], dataset.shape[2]\n",
    "    dataset = dataset.reshape(dataset.shape[0], h, w, 1).astype('float32') / 255\n",
    "\n",
    "    return dataset, h, w\n",
    "\n",
    "dataset, h, w = cnn_preprocess(dataset_x)\n",
    "print dataset.shape, h, w, dataset_y.shape\n",
    "\n",
    "shape = (h, w, 1)\n",
    "output_dim = dataset_y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', input_shape=shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(dataset, dataset_y, test_size=testing_size)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "scores = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "print \"Baseline Error of Validation Set: {:.8f}%\".format(100-scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Multi-Layer CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4217 samples, validate on 2078 samples\n",
      "Epoch 1/8\n",
      "4217/4217 [==============================] - 2s - loss: 1.6391 - acc: 0.4378 - val_loss: 0.8217 - val_acc: 0.7459\n",
      "Epoch 2/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.6959 - acc: 0.7854 - val_loss: 0.5556 - val_acc: 0.8450\n",
      "Epoch 3/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.4104 - acc: 0.8812 - val_loss: 0.3297 - val_acc: 0.9143\n",
      "Epoch 4/8\n",
      "4217/4217 [==============================] - 2s - loss: 0.2998 - acc: 0.9118 - val_loss: 0.2775 - val_acc: 0.9269\n",
      "Epoch 5/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.2269 - acc: 0.9386 - val_loss: 0.2516 - val_acc: 0.9293\n",
      "Epoch 6/8\n",
      "4217/4217 [==============================] - 1s - loss: 0.1731 - acc: 0.9507 - val_loss: 0.2250 - val_acc: 0.9374\n",
      "Epoch 7/8\n",
      "4217/4217 [==============================] - 2s - loss: 0.1480 - acc: 0.9540 - val_loss: 0.2099 - val_acc: 0.9423\n",
      "Epoch 8/8\n",
      "4217/4217 [==============================] - 3s - loss: 0.1113 - acc: 0.9692 - val_loss: 0.1738 - val_acc: 0.9577\n",
      "Baseline Error of Validation Set: 4.23484123%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='valid', input_shape=shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(32, 4, 4, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "scores = model.evaluate(X_validation, y_validation, verbose=0)\n",
    "print \"Baseline Error of Validation Set: {:.8f}%\".format(100-scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
