{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph:\n",
    "\n",
    "## 運算子的摘要清單（Summary List Of Operators）\n",
    "\n",
    "```scala\n",
    "class Graph[VD, ED] {\n",
    "  // Information about the Graph ===================================================================\n",
    "  val numEdges: Long\n",
    "  val numVertices: Long\n",
    "  val inDegrees: VertexRDD[Int]\n",
    "  val outDegrees: VertexRDD[Int]\n",
    "  val degrees: VertexRDD[Int]\n",
    "  \n",
    "  // Views of the graph as collections =============================================================\n",
    "  val vertices: VertexRDD[VD]\n",
    "  val edges: EdgeRDD[ED]\n",
    "  val triplets: RDD[EdgeTriplet[VD, ED]]\n",
    "  \n",
    "  // Functions for caching graphs ==================================================================\n",
    "  def persist(newLevel: StorageLevel = StorageLevel.MEMORY_ONLY): Graph[VD, ED]\n",
    "  def cache(): Graph[VD, ED]\n",
    "  def unpersistVertices(blocking: Boolean = true): Graph[VD, ED]\n",
    "  \n",
    "  // Change the partitioning heuristic  ============================================================\n",
    "  def partitionBy(partitionStrategy: PartitionStrategy): Graph[VD, ED]\n",
    "  \n",
    "  // Transform vertex and edge attributes ==========================================================\n",
    "  def mapVertices[VD2](map: (VertexID, VD) => VD2): Graph[VD2, ED]\n",
    "  def mapEdges[ED2](map: Edge[ED] => ED2): Graph[VD, ED2]\n",
    "  def mapEdges[ED2](map: (PartitionID, Iterator[Edge[ED]]) => Iterator[ED2]): Graph[VD, ED2]\n",
    "  def mapTriplets[ED2](map: EdgeTriplet[VD, ED] => ED2): Graph[VD, ED2]\n",
    "  def mapTriplets[ED2](map: (PartitionID, Iterator[EdgeTriplet[VD, ED]]) => Iterator[ED2])\n",
    "    : Graph[VD, ED2]\n",
    "    \n",
    "  // Modify the graph structure ====================================================================\n",
    "  def reverse: Graph[VD, ED]\n",
    "  def subgraph(\n",
    "      epred: EdgeTriplet[VD,ED] => Boolean = (x => true),\n",
    "      vpred: (VertexID, VD) => Boolean = ((v, d) => true))\n",
    "    : Graph[VD, ED]\n",
    "  def mask[VD2, ED2](other: Graph[VD2, ED2]): Graph[VD, ED]\n",
    "  def groupEdges(merge: (ED, ED) => ED): Graph[VD, ED]\n",
    "  \n",
    "  // Join RDDs with the graph ======================================================================\n",
    "  def joinVertices[U](table: RDD[(VertexID, U)])(mapFunc: (VertexID, VD, U) => VD): Graph[VD, ED]\n",
    "  def outerJoinVertices[U, VD2](other: RDD[(VertexID, U)])\n",
    "      (mapFunc: (VertexID, VD, Option[U]) => VD2)\n",
    "    : Graph[VD2, ED]\n",
    "    \n",
    "  // Aggregate information about adjacent triplets =================================================\n",
    "  def collectNeighborIds(edgeDirection: EdgeDirection): VertexRDD[Array[VertexID]]\n",
    "  def collectNeighbors(edgeDirection: EdgeDirection): VertexRDD[Array[(VertexID, VD)]]\n",
    "  def aggregateMessages[Msg: ClassTag](\n",
    "      sendMsg: EdgeContext[VD, ED, Msg] => Unit,\n",
    "      mergeMsg: (Msg, Msg) => Msg,\n",
    "      tripletFields: TripletFields = TripletFields.All)\n",
    "    : VertexRDD[A]\n",
    "    \n",
    "  // Iterative graph-parallel computation ==========================================================\n",
    "  def pregel[A](initialMsg: A, maxIterations: Int, activeDirection: EdgeDirection)(\n",
    "      vprog: (VertexID, VD, A) => VD,\n",
    "      sendMsg: EdgeTriplet[VD, ED] => Iterator[(VertexID,A)],\n",
    "      mergeMsg: (A, A) => A)\n",
    "    : Graph[VD, ED]\n",
    "    \n",
    "  // Basic graph algorithms ========================================================================\n",
    "  def pageRank(tol: Double, resetProb: Double = 0.15): Graph[Double, Double]\n",
    "  def connectedComponents(): Graph[VertexID, ED]\n",
    "  def triangleCount(): Graph[Int, ED]\n",
    "  def stronglyConnectedComponents(numIter: Int): Graph[VertexID, ED]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VertexRDD:\n",
    "inherits from RDD with two parameters. \n",
    "\n",
    "* VertexID is the ID of vertex, and VD is the type of vertex attribute. \n",
    "* Class VertexRDD defines some methods such as mapVertexPartitions, mapValues and filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EdgeRDD:\n",
    "inherits from RDD with three parameters\n",
    "* ED (the type of edge attribute): the attribute associated with the edge.\n",
    "* sc (source vertex): the ID of the source vertex.\n",
    "* deps (dependencies of the edges, e.g. destination vertices): the ID of the target vertex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EdgeTriplet:\n",
    "* srcAttr is the source vertex attribute, dstAttr is the destination vertex attribute. \n",
    "* Therefore, EdgeTriplet contains those five (three are inherited from Edge) basic attributes.\n",
    "\n",
    "EdgeTriplet equals to Vertex join Edge, which makes EdgeTriplet contains both information of vertices and edges. So it’s useful especially when we want to use the attributes of both the vertex and its connected edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initial Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$exclude.$                        , $ivy.$                            // for cleaner logs\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$profile.$           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // adjust spark version - spark >= 2.0\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      // adjust spark version - spark >= 2.0  // // http://blog.csdn.net/liuxuejiang158blog/article/details/37874557\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                // for JupyterSparkSession (SparkSession aware of the jupyter-scala kernel)\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $exclude.`org.slf4j:slf4j-log4j12`, $ivy.`org.slf4j:slf4j-nop:1.7.21` // for cleaner logs\n",
    "import $profile.`hadoop-2.6`\n",
    "import $ivy.`org.apache.spark::spark-sql:2.1.0` // adjust spark version - spark >= 2.0\n",
    "import $ivy.`org.apache.spark::spark-graphx:2.1.0` // adjust spark version - spark >= 2.0  // // http://blog.csdn.net/liuxuejiang158blog/article/details/37874557\n",
    "import $ivy.`org.apache.hadoop:hadoop-aws:2.6.4`\n",
    "import $ivy.`org.jupyter-scala::spark:0.4.2` // for JupyterSparkSession (SparkSession aware of the jupyter-scala kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.graphx._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.rdd.RDD\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjupyter.spark.session._\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import jupyter.spark.session._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msparkSession\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@326adedb\n",
       "\u001b[36msc\u001b[39m: \u001b[32mSparkContext\u001b[39m = org.apache.spark.SparkContext@42545e00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparkSession = JupyterSparkSession.builder() // important - call this rather than SparkSession.builder()\n",
    "                                      .jupyter() // this method must be called straightaway after builder()\n",
    "                                      // .yarn(\"/etc/hadoop/conf\") // optional, for Spark on YARN - argument is the Hadoop conf directory\n",
    "                                      // .emr(\"2.6.4\") // on AWS ElasticMapReduce, this adds aws-related to the spark jar list\n",
    "                                      .master(\"local\") // change to \"yarn-client\" on YARN\n",
    "                                      // .config(\"spark.executor.instances\", \"10\")\n",
    "                                      // .config(\"spark.executor.memory\", \"3g\")\n",
    "                                      // .config(\"spark.hadoop.fs.s3a.access.key\", awsCredentials._1)\n",
    "                                      // .config(\"spark.hadoop.fs.s3a.secret.key\", awsCredentials._2)\n",
    "                                      .appName(\"jupyter\")\n",
    "                                      .getOrCreate()\n",
    "\n",
    "val sc = sparkSession.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initial Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mvertexArray\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mLong\u001b[39m, (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m))] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m1L\u001b[39m, (\u001b[32m\"RC\"\u001b[39m, \u001b[32m\"Supervisor\"\u001b[39m)),\n",
       "  (\u001b[32m2L\u001b[39m, (\u001b[32m\"TH\"\u001b[39m, \u001b[32m\"Data Analyst\"\u001b[39m)),\n",
       "  (\u001b[32m3L\u001b[39m, (\u001b[32m\"Roger\"\u001b[39m, \u001b[32m\"Data Engineer\"\u001b[39m)),\n",
       "  (\u001b[32m4L\u001b[39m, (\u001b[32m\"Miles\"\u001b[39m, \u001b[32m\"Data Analyst\"\u001b[39m)),\n",
       "  (\u001b[32m5L\u001b[39m, (\u001b[32m\"Amber\"\u001b[39m, \u001b[32m\"Data Analyst\"\u001b[39m)),\n",
       "  (\u001b[32m6L\u001b[39m, (\u001b[32m\"Bgg\"\u001b[39m, \u001b[32m\"Data Analyst\"\u001b[39m)),\n",
       "  (\u001b[32m7L\u001b[39m, (\u001b[32m\"Alex\"\u001b[39m, \u001b[32m\"Data Engineer\"\u001b[39m)),\n",
       "  (\u001b[32m8L\u001b[39m, (\u001b[32m\"Vickie\"\u001b[39m, \u001b[32m\"Data Engineer\"\u001b[39m)),\n",
       "  (\u001b[32m9L\u001b[39m, (\u001b[32m\"Cathay\"\u001b[39m, \u001b[32m\"Company\"\u001b[39m)),\n",
       "  (\u001b[32m10L\u001b[39m, (\u001b[32m\"Python\"\u001b[39m, \u001b[32m\"Programming\"\u001b[39m)),\n",
       "  (\u001b[32m11L\u001b[39m, (\u001b[32m\"Scala\"\u001b[39m, \u001b[32m\"Programming\"\u001b[39m)),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36medgeArray\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mEdge\u001b[39m[\u001b[32mString\u001b[39m]] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m1L\u001b[39m, \u001b[32m\"follower\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m2L\u001b[39m, \u001b[32m\"follower\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m3L\u001b[39m, \u001b[32m\"junior\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m4L\u001b[39m, \u001b[32m\"junior\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m6L\u001b[39m, \u001b[32m\"colleague\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m7L\u001b[39m, \u001b[32m\"colleague\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m5L\u001b[39m, \u001b[32m8L\u001b[39m, \u001b[32m\"colleague\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m1L\u001b[39m, \u001b[32m9L\u001b[39m, \u001b[32m\"worked on\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m2L\u001b[39m, \u001b[32m9L\u001b[39m, \u001b[32m\"worked on\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m3L\u001b[39m, \u001b[32m9L\u001b[39m, \u001b[32m\"worked on\"\u001b[39m),\n",
       "  \u001b[33mEdge\u001b[39m(\u001b[32m4L\u001b[39m, \u001b[32m9L\u001b[39m, \u001b[32m\"worked on\"\u001b[39m),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mvertexRDD\u001b[39m: \u001b[32mRDD\u001b[39m[(\u001b[32mLong\u001b[39m, (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m))] = ParallelCollectionRDD[0] at parallelize at cmd6.sc:40\n",
       "\u001b[36medgeRDD\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mEdge\u001b[39m[\u001b[32mString\u001b[39m]] = ParallelCollectionRDD[1] at parallelize at cmd6.sc:41\n",
       "\u001b[36mgraph\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@28122cb9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 設置節點和邊，節點和邊皆為用 tuple 定義的 Array\n",
    "// 頂點的資料類型是 VD:(String, String)\n",
    "val vertexArray = Array(\n",
    "  (1L, (\"RC\", \"Supervisor\")),\n",
    "  (2L, (\"TH\", \"Data Analyst\")),\n",
    "  (3L, (\"Roger\", \"Data Engineer\")),\n",
    "  (4L, (\"Miles\", \"Data Analyst\")),\n",
    "  (5L, (\"Amber\", \"Data Analyst\")),\n",
    "  (6L, (\"Bgg\", \"Data Analyst\")),\n",
    "  (7L, (\"Alex\", \"Data Engineer\")),\n",
    "  (8L, (\"Vickie\", \"Data Engineer\")),\n",
    "  (9L, (\"Cathay\", \"Company\")),\n",
    "  (10L, (\"Python\", \"Programming\")),\n",
    "  (11L, (\"Scala\", \"Programming\")),\n",
    "  (11L, (\"Scala\", \"Programming\")),\n",
    "  (12L, (\"Java\", \"Programming\")),\n",
    "  (12L, (\"Java\", \"Programming\"))\n",
    ")\n",
    "\n",
    "// 邊的資料類型為 ED: String\n",
    "val edgeArray = Array(\n",
    "  Edge(5L, 1L, \"follower\"),\n",
    "  Edge(5L, 2L, \"follower\"),\n",
    "  Edge(5L, 3L, \"junior\"),\n",
    "  Edge(5L, 4L, \"junior\"),\n",
    "  Edge(5L, 6L, \"colleague\"),\n",
    "  Edge(5L, 7L, \"colleague\"),\n",
    "  Edge(5L, 8L, \"colleague\"),\n",
    "  Edge(1L, 9L, \"worked on\"),\n",
    "  Edge(2L, 9L, \"worked on\"),\n",
    "  Edge(3L, 9L, \"worked on\"),\n",
    "  Edge(4L, 9L, \"worked on\"),\n",
    "  Edge(5L, 9L, \"worked on\"),\n",
    "  Edge(6L, 9L, \"worked on\"),\n",
    "  Edge(7L, 9L, \"worked on\"),\n",
    "  Edge(8L, 9L, \"worked on\"),\n",
    "  Edge(5L, 10L, \"learning\"),\n",
    "  Edge(5L, 11L, \"learning\")\n",
    ")\n",
    "\n",
    "// 構造 vertexRDD 和 edgeRDD\n",
    "val vertexRDD: RDD[(Long, (String, String))] = sc.parallelize(vertexArray)\n",
    "val edgeRDD: RDD[Edge[String]] = sc.parallelize(edgeArray)\n",
    "\n",
    "// 構造圖 Graph[VD,ED]\n",
    "val graph: Graph[(String, String), String] = Graph(vertexRDD, edgeRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertexArray 的資料個數 14\n",
      "edgeArray 的資料個數 17\n",
      "\n",
      "GraphX 會對 vertexRDD 去重複：\n",
      "graph 的節點個數 12\n",
      "graph 的節點個數 12\n",
      "graph 的邊個數 17\n"
     ]
    }
   ],
   "source": [
    "println(s\"vertexArray 的資料個數 ${vertexArray.size}\")\n",
    "println(s\"edgeArray 的資料個數 ${edgeArray.size}\")\n",
    "println\n",
    "println(\"GraphX 會對 vertexRDD 去重複：\")\n",
    "println(s\"graph 的節點個數 ${graph.numVertices}\")\n",
    "println(s\"graph 的節點個數 ${graph.vertices.count}\")\n",
    "println(s\"graph 的邊個數 ${graph.numEdges}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 透過 graph.vertices 和 graph.edges 將圖解構為相應的節點和邊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1). 基本使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,(Miles,Data Analyst))\n",
      "(11,(Scala,Programming))\n",
      "(1,(RC,Supervisor))\n",
      "(6,(Bgg,Data Analyst))\n",
      "(3,(Roger,Data Engineer))\n",
      "(7,(Alex,Data Engineer))\n",
      "(9,(Cathay,Company))\n",
      "(8,(Vickie,Data Engineer))\n",
      "(12,(Java,Programming))\n",
      "(10,(Python,Programming))\n",
      "(5,(Amber,Data Analyst))\n",
      "(2,(TH,Data Analyst))\n"
     ]
    }
   ],
   "source": [
    "graph.vertices.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge(1,9,worked on)\n",
      "Edge(2,9,worked on)\n",
      "Edge(3,9,worked on)\n",
      "Edge(4,9,worked on)\n",
      "Edge(5,1,follower)\n",
      "Edge(5,2,follower)\n",
      "Edge(5,3,junior)\n",
      "Edge(5,4,junior)\n",
      "Edge(5,6,colleague)\n",
      "Edge(5,7,colleague)\n",
      "Edge(5,8,colleague)\n",
      "Edge(5,9,worked on)\n",
      "Edge(5,10,learning)\n",
      "Edge(5,11,learning)\n",
      "Edge(6,9,worked on)\n",
      "Edge(7,9,worked on)\n",
      "Edge(8,9,worked on)\n"
     ]
    }
   ],
   "source": [
    "graph.edges.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1,(RC,Supervisor)),(9,(Cathay,Company)),worked on)\n",
      "((2,(TH,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((3,(Roger,Data Engineer)),(9,(Cathay,Company)),worked on)\n",
      "((4,(Miles,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((5,(Amber,Data Analyst)),(1,(RC,Supervisor)),follower)\n",
      "((5,(Amber,Data Analyst)),(2,(TH,Data Analyst)),follower)\n",
      "((5,(Amber,Data Analyst)),(3,(Roger,Data Engineer)),junior)\n",
      "((5,(Amber,Data Analyst)),(4,(Miles,Data Analyst)),junior)\n",
      "((5,(Amber,Data Analyst)),(6,(Bgg,Data Analyst)),colleague)\n",
      "((5,(Amber,Data Analyst)),(7,(Alex,Data Engineer)),colleague)\n",
      "((5,(Amber,Data Analyst)),(8,(Vickie,Data Engineer)),colleague)\n",
      "((5,(Amber,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((5,(Amber,Data Analyst)),(10,(Python,Programming)),learning)\n",
      "((5,(Amber,Data Analyst)),(11,(Scala,Programming)),learning)\n",
      "((6,(Bgg,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((7,(Alex,Data Engineer)),(9,(Cathay,Company)),worked on)\n",
      "((8,(Vickie,Data Engineer)),(9,(Cathay,Company)),worked on)\n"
     ]
    }
   ],
   "source": [
    "graph.triplets.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2). 搭配使用 Case Class\n",
    "\n",
    "* graph.vertices 返回一個 VertexRDD[(String, String)]，它繼承於 RDD[(VertexID, (String, String))]，可以用 scala 的 case class 解構這個 tuple\n",
    "* graph.edges 返回一個包含 Edge[String] 物件的 EdgeRDD，也可以使用 case class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找出圖中為「Data Analyst」的節點：\n",
      "Miles is a Data Analyst.\n",
      "Bgg is a Data Analyst.\n",
      "Amber is a Data Analyst.\n",
      "TH is a Data Analyst.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres16_2\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m4L\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"找出圖中為「Data Analyst」的節點：\")\n",
    "\n",
    "graph.vertices.filter { \n",
    "  case (id, (name, title)) => title == \"Data Analyst\"\n",
    "}.collect.foreach {\n",
    "  case (id, (name, title)) => println(s\"$name is a $title.\")\n",
    "}\n",
    "\n",
    "graph.vertices.filter { \n",
    "  case (id, (name, title)) => title == \"Data Analyst\"\n",
    "}.count  // 個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找出圖中屬性為「worked on」的邊：\n",
      "1 to 9 att: worked on\n",
      "2 to 9 att: worked on\n",
      "3 to 9 att: worked on\n",
      "4 to 9 att: worked on\n",
      "5 to 9 att: worked on\n",
      "6 to 9 att: worked on\n",
      "7 to 9 att: worked on\n",
      "8 to 9 att: worked on\n"
     ]
    }
   ],
   "source": [
    "println(\"[Method1] 找出圖中屬性為「worked on」的邊：\")\n",
    "\n",
    "graph.edges.filter{ \n",
    "  case Edge(src, dst, relation) => relation == \"worked on\"\n",
    "}.collect.foreach{\n",
    "  case Edge(src, dst, relation) => println(s\"${src} to ${dst} att: ${relation}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Method2] 找出圖中屬性為「worked on」的邊：\n",
      "1 to 9 attr: worked on\n",
      "2 to 9 attr: worked on\n",
      "3 to 9 attr: worked on\n",
      "4 to 9 attr: worked on\n",
      "5 to 9 attr: worked on\n",
      "6 to 9 attr: worked on\n",
      "7 to 9 attr: worked on\n",
      "8 to 9 attr: worked on\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres19_2\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m8L\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"[Method2] 找出圖中屬性為「worked on」的邊：\")\n",
    "\n",
    "// Edge 案例類別(case class)：邊有一個 srcId 和 dstId 分別對應於來源和目標節點的辨識碼。\n",
    "// 另外，Edge 類別有一個 attr 成員用來儲存邊的屬性。\n",
    "graph.edges.filter(e => e.attr == \"worked on\").collect.foreach{\n",
    "    e => println(s\"${e.srcId} to ${e.dstId} attr: ${e.attr}\")\n",
    "}\n",
    "\n",
    "graph.edges.filter(e => e.attr == \"worked on\").count // 個數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3). EdgeTriplet 類別繼承於 Edge 類別，並且加入 srcAttr 和 dstAttr 成员，這兩個成員分別包含來源和目的的屬性\n",
    "\n",
    "EdgeTriplet 對於 vertices 和 edges 的連接操作，使得 Triplet 具備「來源節點」的 ID 和屬性、「目的節點」的 ID 和屬性、edge 的屬性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// graph.triplets.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RC is worked on Cathay\n",
      "TH is worked on Cathay\n",
      "Roger is worked on Cathay\n",
      "Miles is worked on Cathay\n",
      "Amber is the follower of RC\n",
      "Amber is the follower of TH\n",
      "Amber is the junior of Roger\n",
      "Amber is the junior of Miles\n",
      "Amber is the colleague of Bgg\n",
      "Amber is the colleague of Alex\n",
      "Amber is the colleague of Vickie\n",
      "Amber is worked on Cathay\n",
      "Amber is learning Python\n",
      "Amber is learning Scala\n",
      "Bgg is worked on Cathay\n",
      "Alex is worked on Cathay\n",
      "Vickie is worked on Cathay\n",
      "\n",
      "RC is worked on Cathay\n",
      "TH is worked on Cathay\n",
      "Roger is worked on Cathay\n",
      "Miles is worked on Cathay\n",
      "Amber is the follower of RC\n",
      "Amber is the follower of TH\n",
      "Amber is the junior of Roger\n",
      "Amber is the junior of Miles\n",
      "Amber is the colleague of Bgg\n",
      "Amber is the colleague of Alex\n",
      "Amber is the colleague of Vickie\n",
      "Amber is worked on Cathay\n",
      "Amber is learning Python\n",
      "Amber is learning Scala\n",
      "Bgg is worked on Cathay\n",
      "Alex is worked on Cathay\n",
      "Vickie is worked on Cathay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mfacts\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mString\u001b[39m] = MapPartitionsRDD[43] at map at cmd25.sc:2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 在 tuple 中，可以用方法_1, _2, _3 訪問其中的元素\n",
    "val facts: RDD[String] =\n",
    "  graph.triplets.map(\n",
    "    triplet =>\n",
    "        // triplets 操作：((srcId, srcAttr), (dstId, dstAttr), attr)\n",
    "        if (triplet.attr == \"worked on\" || triplet.attr == \"learning\") { \n",
    "            triplet.srcAttr._1 + \" is \" + triplet.attr + \" \" + triplet.dstAttr._1\n",
    "        } else{\n",
    "            triplet.srcAttr._1 + \" is the \" + triplet.attr + \" of \" + triplet.dstAttr._1\n",
    "        }    \n",
    "  )\n",
    "\n",
    "facts.collect.foreach(println(_))\n",
    "println\n",
    "// 等價於\n",
    "facts.collect.foreach(e => println(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.2) for loop 寫法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RC is worked on Cathay\n",
      "TH is worked on Cathay\n",
      "Roger is worked on Cathay\n",
      "Miles is worked on Cathay\n",
      "Amber is worked on Cathay\n",
      "Bgg is worked on Cathay\n",
      "Alex is worked on Cathay\n",
      "Vickie is worked on Cathay\n"
     ]
    }
   ],
   "source": [
    "// triplets 操作，((srcId, srcAttr), (dstId, dstAttr), attr)\n",
    "for (triplet <- graph.triplets.filter(t => t.attr == \"worked on\").collect) {\n",
    "  println(s\"${triplet.srcAttr._1} is ${triplet.attr} ${triplet.dstAttr._1}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "備註："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "// The Scala spec says that ← (unicode \\u2190) is reserved as is its ascii equivalent <- which as others are also pointing out, \n",
    "// is an iterator for a for loop.\n",
    "for(x <- 1 to 5)  println(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 圖形操作（Graph Operators）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1). 分支度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外分支度 (outDegrees): \n",
      "(4,1)\n",
      "(1,1)\n",
      "(6,1)\n",
      "(3,1)\n",
      "(7,1)\n",
      "(8,1)\n",
      "(5,10)\n",
      "(2,1)\n",
      "內分支度 (inDegrees): \n",
      "(4,1)\n",
      "(11,1)\n",
      "(1,1)\n",
      "(6,1)\n",
      "(3,1)\n",
      "(7,1)\n",
      "(9,8)\n",
      "(8,1)\n",
      "(10,1)\n",
      "(2,1)\n",
      "分支度 (degrees): \n",
      "(4,2)\n",
      "(11,1)\n",
      "(1,2)\n",
      "(6,2)\n",
      "(3,2)\n",
      "(7,2)\n",
      "(9,8)\n",
      "(8,2)\n",
      "(10,1)\n",
      "(5,10)\n",
      "(2,2)\n"
     ]
    }
   ],
   "source": [
    "println(\"外分支度 (outDegrees): \")\n",
    "graph.outDegrees.collect.foreach(println(_))\n",
    "\n",
    "println(\"內分支度 (inDegrees): \")\n",
    "graph.inDegrees.collect.foreach(println(_))\n",
    "\n",
    "println(\"分支度 (degrees): \")\n",
    "graph.degrees.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找出圖中擁有最大 outDegree, inDegree, Degree 的節點：\n",
      "max of outDegrees:(5,10)\n",
      "max of inDegrees:(9,8)\n",
      "max of Degrees:(5,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmax\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"找出圖中擁有最大 outDegree, inDegree, Degree 的節點：\")\n",
    "\n",
    "def max(a: (VertexId, Int), b: (VertexId, Int)): (VertexId, Int) = {\n",
    "  if (a._2 > b._2) a else b\n",
    "}\n",
    "\n",
    "println(\"max of outDegrees:\" + graph.outDegrees.reduce(max))\n",
    "println(\"max of inDegrees:\" + graph.inDegrees.reduce(max))\n",
    "println(\"max of Degrees:\" + graph.degrees.reduce(max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2). 屬性運算子（Property Operators）\n",
    "類似 RDD 的 map 運算子，如下列所示：\n",
    "```scala\n",
    "class Graph[VD, ED] {\n",
    "  def mapVertices[VD2](map: (VertexId, VD) => VD2): Graph[VD2, ED]\n",
    "  def mapEdges[ED2](map: Edge[ED] => ED2): Graph[VD, ED2]\n",
    "  def mapTriplets[ED2](map: EdgeTriplet[VD, ED] => ED2): Graph[VD, ED2]\n",
    "}\n",
    "```\n",
    "\n",
    "每個運算子執行後都會產生一個新的圖形，其頂點或邊的屬性都會經過使用者所定義的 map 函數而改變。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) mapVertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "簡單的頂點轉換操作：\n",
      "4 is (Miles,Data AnalystData Analyst)\n",
      "11 is (Scala,ProgrammingProgramming)\n",
      "1 is (RC,SupervisorSupervisor)\n",
      "6 is (Bgg,Data AnalystData Analyst)\n",
      "3 is (Roger,Data EngineerData Engineer)\n",
      "7 is (Alex,Data EngineerData Engineer)\n",
      "9 is (Cathay,CompanyCompany)\n",
      "8 is (Vickie,Data EngineerData Engineer)\n",
      "12 is (Java,ProgrammingProgramming)\n",
      "10 is (Python,ProgrammingProgramming)\n",
      "5 is (Amber,Data AnalystData Analyst)\n",
      "2 is (TH,Data AnalystData Analyst)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres42_0\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mVertexId\u001b[39m, (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@60f1fc96"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.mapVertices{ \n",
    "  case (id, (name, title)) => (id, (name, title*2)) \n",
    "}\n",
    "\n",
    "println(\"簡單的頂點轉換操作：\")\n",
    "\n",
    "graph.mapVertices{ \n",
    "  case (id, (name, title)) => (id, (name, title*2)) \n",
    "}.vertices.collect.foreach(v => println(s\"${v._2._1} is ${v._2._2}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "較複雜的頂點轉換操作，由頂點的職位計算出年薪：\n",
      "Vertex ID No.4 is (Miles,Data Analyst,2000000)\n",
      "Vertex ID No.11 is (Scala,Programming,0)\n",
      "Vertex ID No.1 is (RC,Supervisor,5000000)\n",
      "Vertex ID No.6 is (Bgg,Data Analyst,2000000)\n",
      "Vertex ID No.3 is (Roger,Data Engineer,2000000)\n",
      "Vertex ID No.7 is (Alex,Data Engineer,2000000)\n",
      "Vertex ID No.9 is (Cathay,Company,0)\n",
      "Vertex ID No.8 is (Vickie,Data Engineer,2000000)\n",
      "Vertex ID No.12 is (Java,Programming,0)\n",
      "Vertex ID No.10 is (Python,Programming,0)\n",
      "Vertex ID No.5 is (Amber,Data Analyst,2000000)\n",
      "Vertex ID No.2 is (TH,Data Analyst,2000000)\n"
     ]
    }
   ],
   "source": [
    "println(\"較複雜的頂點轉換操作，由頂點的職位計算出年薪：\")\n",
    "graph.mapVertices{ \n",
    "  case (id, (name, title)) => if (title == \"Supervisor\") (id, (name, title, 5000000)) \n",
    "                              else if (title == \"Data Engineer\" || title == \"Data Analyst\") (id, (name, title, 2000000))  \n",
    "                              else (id, (name, title, 0))\n",
    "}.vertices.collect.foreach(v => println(s\"Vertex ID No.${v._2._1} is ${v._2._2}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "較複雜的頂點轉換操作，由頂點的職位計算出年薪（另一種寫法 Pattern Matching ）：\n",
      "Vertex ID No.4 is (Miles,Data Analyst,2000000)\n",
      "Vertex ID No.11 is (Scala,Programming,0)\n",
      "Vertex ID No.1 is (RC,Supervisor,5000000)\n",
      "Vertex ID No.6 is (Bgg,Data Analyst,2000000)\n",
      "Vertex ID No.3 is (Roger,Data Engineer,2000000)\n",
      "Vertex ID No.7 is (Alex,Data Engineer,2000000)\n",
      "Vertex ID No.9 is (Cathay,Company,0)\n",
      "Vertex ID No.8 is (Vickie,Data Engineer,2000000)\n",
      "Vertex ID No.12 is (Java,Programming,0)\n",
      "Vertex ID No.10 is (Python,Programming,0)\n",
      "Vertex ID No.5 is (Amber,Data Analyst,2000000)\n",
      "Vertex ID No.2 is (TH,Data Analyst,2000000)\n"
     ]
    }
   ],
   "source": [
    "println(\"較複雜的頂點轉換操作，由頂點的職位計算出年薪（另一種寫法 Pattern Matching ）：\")\n",
    "graph.mapVertices{ \n",
    "  case (id, (name, title)) => title match {\n",
    "                                    case \"Supervisor\" => (id, (name, title, 5000000))\n",
    "                                    case \"Data Engineer\" | \"Data Analyst\" => (id, (name, title, 2000000))\n",
    "                                    case _ => (id, (name, title, 0)) \n",
    "                                }\n",
    "    }.vertices.collect.foreach(v => println(s\"Vertex ID No.${v._2._1} is ${v._2._2}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) mapEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "簡單的邊轉換操作，由邊的屬性計算出：\n",
      "1 to 9 attr: WORKED ON\n",
      "2 to 9 attr: WORKED ON\n",
      "3 to 9 attr: WORKED ON\n",
      "4 to 9 attr: WORKED ON\n",
      "5 to 1 attr: FOLLOWER\n",
      "5 to 2 attr: FOLLOWER\n",
      "5 to 3 attr: JUNIOR\n",
      "5 to 4 attr: JUNIOR\n",
      "5 to 6 attr: COLLEAGUE\n",
      "5 to 7 attr: COLLEAGUE\n",
      "5 to 8 attr: COLLEAGUE\n",
      "5 to 9 attr: WORKED ON\n",
      "5 to 10 attr: LEARNING\n",
      "5 to 11 attr: LEARNING\n",
      "6 to 9 attr: WORKED ON\n",
      "7 to 9 attr: WORKED ON\n",
      "8 to 9 attr: WORKED ON\n"
     ]
    }
   ],
   "source": [
    "println(\"簡單的邊轉換操作，由邊的屬性計算出：\")\n",
    "graph.mapEdges(e => e.attr.toUpperCase)\n",
    "  .edges.collect.foreach(e => println(s\"${e.srcId} to ${e.dstId} attr: ${e.attr}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) 補充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miles is Data Analyst, and his/her salary is 2000000\n",
      "Scala is Programming, and his/her salary is 0\n",
      "RC is Supervisor, and his/her salary is 5000000\n",
      "Bgg is Data Analyst, and his/her salary is 2000000\n",
      "Roger is Data Engineer, and his/her salary is 2000000\n",
      "Alex is Data Engineer, and his/her salary is 2000000\n",
      "Cathay is Company, and his/her salary is 0\n",
      "Vickie is Data Engineer, and his/her salary is 2000000\n",
      "Java is Programming, and his/her salary is 0\n",
      "Python is Programming, and his/her salary is 0\n",
      "Amber is Data Analyst, and his/her salary is 2000000\n",
      "TH is Data Analyst, and his/her salary is 2000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewVertices\u001b[39m: \u001b[32mRDD\u001b[39m[(\u001b[32mVertexId\u001b[39m, (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m))] = MapPartitionsRDD[57] at map at cmd30.sc:1\n",
       "\u001b[36mnewGraph1\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@7961f66a"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 注意，在經過這些操作下，是不會影響到圖形的結構。這些運算子有一個重要特色，就是它會重複利用原始圖形結構的索引值。\n",
    "// 下面的兩段程式碼目的上是相同的，但是第一段並不會保存結構的索引值，這樣將無法讓 GraphX 系統優化。\n",
    "\n",
    "// Method1: map\n",
    "// 第一段並不會保存結構的索引值，將無法讓 GraphX 系統優化\n",
    "val newVertices = graph.vertices.map { \n",
    "  case (id, (name, title)) => if (title == \"Supervisor\") (id, (name, title, 5000000)) \n",
    "                              else if (title == \"Data Engineer\" || title == \"Data Analyst\") (id, (name, title, 2000000))  \n",
    "                              else (id, (name, title, 0))  \n",
    "}\n",
    "val newGraph1 = Graph(newVertices, graph.edges)\n",
    "\n",
    "newGraph1.vertices.collect.foreach(v => println(s\"${v._2._1} is ${v._2._2}, and his/her salary is ${v._2._3}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miles is Data Analyst, and his/her salary is 2000000\n",
      "Scala is Programming, and his/her salary is 0\n",
      "RC is Supervisor, and his/her salary is 5000000\n",
      "Bgg is Data Analyst, and his/her salary is 2000000\n",
      "Roger is Data Engineer, and his/her salary is 2000000\n",
      "Alex is Data Engineer, and his/her salary is 2000000\n",
      "Cathay is Company, and his/her salary is 0\n",
      "Vickie is Data Engineer, and his/her salary is 2000000\n",
      "Java is Programming, and his/her salary is 0\n",
      "Python is Programming, and his/her salary is 0\n",
      "Amber is Data Analyst, and his/her salary is 2000000\n",
      "TH is Data Analyst, and his/her salary is 2000000\n",
      "\n",
      "(4,(Miles,Data Analyst,2000000))\n",
      "(11,(Scala,Programming,0))\n",
      "(1,(RC,Supervisor,5000000))\n",
      "(6,(Bgg,Data Analyst,2000000))\n",
      "(3,(Roger,Data Engineer,2000000))\n",
      "(7,(Alex,Data Engineer,2000000))\n",
      "(9,(Cathay,Company,0))\n",
      "(8,(Vickie,Data Engineer,2000000))\n",
      "(12,(Java,Programming,0))\n",
      "(10,(Python,Programming,0))\n",
      "(5,(Amber,Data Analyst,2000000))\n",
      "(2,(TH,Data Analyst,2000000))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewGraph\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@6af26eaf"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Method2:\n",
    "// 另一種方法是透過 mapVertices⇒VD2)(ClassTag[VD2]):Graph[VD2,ED]) 來保存索引。\n",
    "\n",
    "// val newGraph2 = graph.mapVertices{\n",
    "//                                   case (id, (name, title)) => if (title == \"Supervisor\") (name, title, 5000000)\n",
    "//                                                               else if (title == \"Data Engineer\" || title == \"Data Analyst\") (name, title, 2000000) \n",
    "//                                                               else (name, title, 0)\n",
    "//                                   }\n",
    "\n",
    "val newGraph = graph.mapVertices{ \n",
    "  case (id, (name, title)) => title match {\n",
    "                                            case \"Supervisor\" => (name, title, 5000000) //(id, (name, title, 5000000))\n",
    "                                            case \"Data Engineer\" | \"Data Analyst\" => (name, title, 2000000) //(id, (name, title, 2000000))\n",
    "                                            case _ => (name, title, 0) //(id, (name, title, 0)) \n",
    "                                           }\n",
    "}\n",
    "\n",
    "newGraph.vertices.collect.foreach(v => println(s\"${v._2._1} is ${v._2._2}, and his/her salary is ${v._2._3}\"))\n",
    "println\n",
    "newGraph.vertices.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3). 結構性運算子（Structural Operators）\n",
    "\n",
    "下面列出了基本的結構性運算子：\n",
    "```scala\n",
    "class Graph[VD, ED] {\n",
    "  def reverse: Graph[VD, ED]\n",
    "  def subgraph(epred: EdgeTriplet[VD,ED] => Boolean,\n",
    "               vpred: (VertexId, VD) => Boolean): Graph[VD, ED]\n",
    "  def mask[VD2, ED2](other: Graph[VD2, ED2]): Graph[VD, ED]\n",
    "  def groupEdges(merge: (ED, ED) => ED): Graph[VD,ED]\n",
    "}\n",
    "```\n",
    "* reverse：此運算子將會反轉圖形內所有邊的方向並回傳反轉後的圖形。例如，這個操作可以用來計算反轉後的 PageRank。由於這個操作並不會修改到頂點或是邊，也不會改變邊的數量，所以能夠在不搬移或複製資料的情況下有效率地實現。\n",
    "\n",
    "* subgraph⇒Boolean,(VertexId,VD)⇒Boolean):Graph[VD,ED])：此運算子會利用使用者給予的頂點和邊的條件（predicateds），回傳的圖形是滿足條件的頂點和邊，以及滿足頂點條件的相連頂點。subgraph 運算子可以在許多情況上，限制有興趣的頂點和邊或刪除受損的連結。\n",
    "\n",
    "* groupEdges⇒ED):Graph[VD,ED])：此運算子會合併平行的邊（如一對頂點間重複的邊）。在許多應用上，會藉由將平行的邊合併（權值合併）為一條來降低圖形的大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "節點為「Data Analyst」的子圖：\n",
      "((5,(Amber,Data Analyst)),(2,(TH,Data Analyst)),follower)\n",
      "((5,(Amber,Data Analyst)),(4,(Miles,Data Analyst)),junior)\n",
      "((5,(Amber,Data Analyst)),(6,(Bgg,Data Analyst)),colleague)\n",
      "\n",
      "子圖中所有的節點：\n",
      "Miles is Data Analyst\n",
      "Bgg is Data Analyst\n",
      "Amber is Data Analyst\n",
      "TH is Data Analyst\n",
      "\n",
      "子圖中所有的邊：\n",
      "5 to 2 attr: follower\n",
      "5 to 4 attr: junior\n",
      "5 to 6 attr: colleague\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36msubGraph\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@54535be4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"節點為「Data Analyst」的子圖：\")\n",
    "// 注意，該例子只有提供頂點的條件。如果沒有給予頂點或邊的條件，subgraph 運算子預設為 True，代表不會做任何限制。\n",
    "val subGraph = graph.subgraph(vpred = (id, vd) => vd._2 == \"Data Analyst\")\n",
    "subGraph.triplets.collect.foreach(println(_))\n",
    "println\n",
    "println(\"子圖中所有的節點：\")\n",
    "subGraph.vertices.collect.foreach(v => println(s\"${v._2._1} is ${v._2._2}\"))\n",
    "println\n",
    "println(\"子圖中所有的邊：\")\n",
    "subGraph.edges.collect.foreach(e => println(s\"${e.srcId} to ${e.dstId} attr: ${e.attr}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邊為「worked on」的子圖：\n",
      "((1,(RC,Supervisor)),(9,(Cathay,Company)),worked on)\n",
      "((2,(TH,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((3,(Roger,Data Engineer)),(9,(Cathay,Company)),worked on)\n",
      "((4,(Miles,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((5,(Amber,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((6,(Bgg,Data Analyst)),(9,(Cathay,Company)),worked on)\n",
      "((7,(Alex,Data Engineer)),(9,(Cathay,Company)),worked on)\n",
      "((8,(Vickie,Data Engineer)),(9,(Cathay,Company)),worked on)\n",
      "\n",
      "子圖中所有的節點：\n",
      "Miles is Data Analyst\n",
      "Scala is Programming\n",
      "RC is Supervisor\n",
      "Bgg is Data Analyst\n",
      "Roger is Data Engineer\n",
      "Alex is Data Engineer\n",
      "Cathay is Company\n",
      "Vickie is Data Engineer\n",
      "Java is Programming\n",
      "Python is Programming\n",
      "Amber is Data Analyst\n",
      "TH is Data Analyst\n",
      "\n",
      "子圖中所有的邊：\n",
      "1 to 9 attr: worked on\n",
      "2 to 9 attr: worked on\n",
      "3 to 9 attr: worked on\n",
      "4 to 9 attr: worked on\n",
      "5 to 9 attr: worked on\n",
      "6 to 9 attr: worked on\n",
      "7 to 9 attr: worked on\n",
      "8 to 9 attr: worked on\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36msubGraph2\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@65c50106"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"邊為「worked on」的子圖：\")\n",
    "val subGraph2 = graph.subgraph(epred = e => e.attr == \"worked on\")  // e.srcId != e.dstId\n",
    "subGraph2.triplets.collect.foreach(println(_))\n",
    "println\n",
    "println(\"子圖中所有的節點：\")\n",
    "subGraph2.vertices.collect.foreach(v => println(s\"${v._2._1} is ${v._2._2}\"))\n",
    "println\n",
    "println(\"子圖中所有的邊：\")\n",
    "subGraph2.edges.collect.foreach(e => println(s\"${e.srcId} to ${e.dstId} attr: ${e.attr}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.2)\n",
    "以下範例說明如何刪除受損的連結："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36musers\u001b[39m: \u001b[32mRDD\u001b[39m[(\u001b[32mVertexId\u001b[39m, (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m))] = ParallelCollectionRDD[150] at parallelize at cmd51.sc:2\n",
       "\u001b[36mrelationships\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mEdge\u001b[39m[\u001b[32mString\u001b[39m]] = ParallelCollectionRDD[151] at parallelize at cmd51.sc:8\n",
       "\u001b[36mdefaultUser\u001b[39m: (\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m) = (\u001b[32m\"John Doe\"\u001b[39m, \u001b[32m\"Missing\"\u001b[39m)\n",
       "\u001b[36mdemoGraph\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@1a96f8ba"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create an RDD for the vertices\n",
    "val users: RDD[(VertexId, (String, String))] =\n",
    "  sc.parallelize(Array((3L, (\"rxin\", \"student\")), (7L, (\"jgonzal\", \"postdoc\")),\n",
    "                       (5L, (\"franklin\", \"prof\")), (2L, (\"istoica\", \"prof\")),\n",
    "                       (4L, (\"peter\", \"student\"))))\n",
    "\n",
    "// Create an RDD for edges\n",
    "val relationships: RDD[Edge[String]] =\n",
    "  sc.parallelize(Array(Edge(3L, 7L, \"collab\"),    Edge(5L, 3L, \"advisor\"),\n",
    "                       Edge(2L, 5L, \"colleague\"), Edge(5L, 7L, \"pi\"),\n",
    "                       Edge(4L, 0L, \"student\"),   Edge(5L, 0L, \"colleague\")))\n",
    "\n",
    "// Define a default user in case there are relationship with missing user\n",
    "val defaultUser = (\"John Doe\", \"Missing\")\n",
    "\n",
    "// Build the initial Graph\n",
    "val demoGraph = Graph(users, relationships, defaultUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,(peter,student))\n",
      "(0,(John Doe,Missing))\n",
      "(3,(rxin,student))\n",
      "(7,(jgonzal,postdoc))\n",
      "(5,(franklin,prof))\n",
      "(2,(istoica,prof))\n",
      "\n",
      "istoica is the colleague of franklin\n",
      "rxin is the collab of jgonzal\n",
      "peter is the student of John Doe\n",
      "franklin is the colleague of John Doe\n",
      "franklin is the advisor of rxin\n",
      "franklin is the pi of jgonzal\n"
     ]
    }
   ],
   "source": [
    "// Notice that there is a user 0 (for which we have no information) connected to users 4 (peter) and 5 (franklin).\n",
    "demoGraph.vertices.collect.foreach(println(_))\n",
    "println()\n",
    "demoGraph.triplets.map(\n",
    "  triplet => triplet.srcAttr._1 + \" is the \" + triplet.attr + \" of \" + triplet.dstAttr._1\n",
    ").collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,(peter,student))\n",
      "(3,(rxin,student))\n",
      "(7,(jgonzal,postdoc))\n",
      "(5,(franklin,prof))\n",
      "(2,(istoica,prof))\n",
      "\n",
      "istoica is the colleague of franklin\n",
      "rxin is the collab of jgonzal\n",
      "franklin is the advisor of rxin\n",
      "franklin is the pi of jgonzal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mvalidGraph\u001b[39m: \u001b[32mGraph\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@bfc634a"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Remove missing vertices as well as the edges to connected to them\n",
    "val validGraph = demoGraph.subgraph(vpred = (id, attr) => attr._2 != \"Missing\")\n",
    "\n",
    "// The valid subgraph will disconnect users 4 and 5 by removing user 0\n",
    "validGraph.vertices.collect.foreach(println(_))\n",
    "println()\n",
    "validGraph.triplets.map(\n",
    "  triplet => triplet.srcAttr._1 + \" is the \" + triplet.attr + \" of \" + triplet.dstAttr._1\n",
    ").collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (4). Join運算子（Join Operators）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在許多情況下，必須將外部的資料合併到圖中。例如，可能會想將額外的使用者資訊合併到現有的圖中，或是想從一個圖中取出資訊加到另一個圖中。\n",
    "\n",
    "這些任務都可以藉由join運算子來完成。\n",
    "\n",
    "以下列出join運算子主要的功能。\n",
    "```scala\n",
    "class Graph[VD, ED] {\n",
    "  def joinVertices[U](table: RDD[(VertexId, U)])(map: (VertexId, VD, U) => VD)\n",
    "    : Graph[VD, ED]\n",
    "  def outerJoinVertices[U, VD2](table: RDD[(VertexId, U)])(map: (VertexId, VD, Option[U]) => VD2)\n",
    "    : Graph[VD2, ED]\n",
    "}\n",
    "```\n",
    "\n",
    "* joinVertices])((VertexId,VD,U)⇒VD)(ClassTag[U]):Graph[VD,ED])：此運算子會將輸入的 RDD 和頂點作結合，回傳一個透過使用者定義的 map 函數所轉換後的頂點的圖。若頂點沒有匹配值則會保留其原始值。\n",
    "\n",
    "* 除了將使用者自定義的 map 函數套用到所有的頂點和改變頂點屬性類型外，更一般的 outerJoinVertices])((VertexId,VD,Option[U])⇒VD2)(ClassTag[U],ClassTag[VD2]):Graph[VD2,ED]) 的用法與 joinVertices 類似。因為並非所有頂點在 RDD 中都有匹配值，map 函數需要一個option 型別參數。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// newGraph.vertices.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mUser\u001b[39m\n",
       "\u001b[36minitialUserGraph\u001b[39m: \u001b[32mGraph\u001b[39m[\u001b[32mwrapper\u001b[39m.\u001b[32mwrapper\u001b[39m.\u001b[32mUser\u001b[39m, \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@6301c3d1\n",
       "\u001b[36muserGraph\u001b[39m: \u001b[32mGraph\u001b[39m[\u001b[32mwrapper\u001b[39m.\u001b[32mwrapper\u001b[39m.\u001b[32mUser\u001b[39m, \u001b[32mString\u001b[39m] = org.apache.spark.graphx.impl.GraphImpl@47cb0b5c"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class User(name: String, title: String, salary: Int, inDeg: Int, outDeg: Int)\n",
    "\n",
    "// 創建一個新圖，節點的數據類型為 User，並從原圖 newGraph 做類型轉換\n",
    "val initialUserGraph: Graph[User, String] = newGraph.mapVertices { case (id, (name, title, salary)) => User(name, title, salary, 0, 0)}\n",
    "\n",
    "// 檢視資訊\n",
    "// initialUserGraph.vertices.collect.foreach(println(_))\n",
    "// println\n",
    "// initialUserGraph.edges.collect.foreach(println(_))\n",
    "\n",
    "//initialUserGraph 與 inDegrees、outDegrees（RDD）進行連接，並修改 initialUserGraph 中 inDeg值、outDeg值\n",
    "val userGraph = initialUserGraph.outerJoinVertices(initialUserGraph.inDegrees) {\n",
    "  case (id, user, inDegOpt) => User(user.name, user.title, user.salary, inDegOpt.getOrElse(0), user.outDeg) // 此時，user.outDeg 必為 0\n",
    "}.outerJoinVertices(initialUserGraph.outDegrees) {\n",
    "  case (id, user, outDegOpt) => User(user.name, user.title, user.salary, user.inDeg, outDegOpt.getOrElse(0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// 兩者的內容相同\n",
    "// initialUserGraph.inDegrees.collect.foreach(println(_)) == graph.inDegrees.collect.foreach(println(_))\n",
    "// println\n",
    "// initialUserGraph.outDegrees.collect.foreach(println(_)) == graph.outDegrees.collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,User(Miles,Data Analyst,2000000,1,1))\n",
      "(11,User(Scala,Programming,0,1,0))\n",
      "(1,User(RC,Supervisor,5000000,1,1))\n",
      "(6,User(Bgg,Data Analyst,2000000,1,1))\n",
      "(3,User(Roger,Data Engineer,2000000,1,1))\n",
      "(7,User(Alex,Data Engineer,2000000,1,1))\n",
      "(9,User(Cathay,Company,0,8,0))\n",
      "(8,User(Vickie,Data Engineer,2000000,1,1))\n",
      "(12,User(Java,Programming,0,0,0))\n",
      "(10,User(Python,Programming,0,1,0))\n",
      "(5,User(Amber,Data Analyst,2000000,0,10))\n",
      "(2,User(TH,Data Analyst,2000000,1,1))\n",
      "\n",
      "圖的屬性：\n",
      "Miles inDeg: 1  outDeg: 1\n",
      "Scala inDeg: 1  outDeg: 0\n",
      "RC inDeg: 1  outDeg: 1\n",
      "Bgg inDeg: 1  outDeg: 1\n",
      "Roger inDeg: 1  outDeg: 1\n",
      "Alex inDeg: 1  outDeg: 1\n",
      "Cathay inDeg: 8  outDeg: 0\n",
      "Vickie inDeg: 1  outDeg: 1\n",
      "Java inDeg: 0  outDeg: 0\n",
      "Python inDeg: 1  outDeg: 0\n",
      "Amber inDeg: 0  outDeg: 10\n",
      "TH inDeg: 1  outDeg: 1\n"
     ]
    }
   ],
   "source": [
    "// 檢視資訊\n",
    "userGraph.vertices.collect.foreach(println(_))\n",
    "println\n",
    "println(\"圖的屬性：\")\n",
    "userGraph.vertices.collect.foreach(v => println(s\"${v._2.name} inDeg: ${v._2.inDeg}  outDeg: ${v._2.outDeg}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外分支度和內分支度相同的節點：\n",
      "Miles\n",
      "RC\n",
      "Bgg\n",
      "Roger\n",
      "Alex\n",
      "Vickie\n",
      "Java\n",
      "TH\n"
     ]
    }
   ],
   "source": [
    "println(\"外分支度和內分支度相同的節點：\")\n",
    "userGraph.vertices.filter {\n",
    "  case (id, user) => user.inDeg == user.outDeg\n",
    "}.collect.foreach {\n",
    "  case (id, user) => println(user.name)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5). 相鄰聚合（Neighborhood Aggregation）\n",
    "\n",
    "匯集每個頂點周圍的資訊。例如，可能想知道每個使用者的追隨者數量或是平均年薪。許多的迭代圖形演算法（如PageRank、最短路徑（Shortest Path）和連通分量（Connected Components））重複的匯集相鄰頂點（如PageRank的值、到來源的最短路徑、最小可到達的頂點id）的資訊。\n",
    "\n",
    "為了改善效能，將主要的聚合運算子從 graph.mapReduceTriplets 改成新的 graph.AggregateMessages。\n",
    "\n",
    "### 聚合訊息(aggregateMessages)\n",
    "\n",
    "GraphX 中的核心聚合運算是 aggregateMessages⇒Unit,(A,A)⇒A,TripletFields)(ClassTag[A]):VertexRDD[A])。這個運算子在圖形的每個edge triplet 應用一個使用者自定義的 sendMsg 函數，然後也應用 mergeMsg 函數去匯集目標頂點的資訊。\n",
    "\n",
    "```scala\n",
    "class Graph[VD, ED] {\n",
    "  def aggregateMessages[Msg: ClassTag](\n",
    "      sendMsg: EdgeContext[VD, ED, Msg] => Unit,\n",
    "      mergeMsg: (Msg, Msg) => Msg,\n",
    "      tripletFields: TripletFields = TripletFields.All)\n",
    "    : VertexRDD[Msg]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "* 使用者自定義的 sendMsg 函數接受一個 EdgeContext 型別，EdgeContext 透露了起始和目標的屬性以及傳送訊息給起始和目標屬性的函數 （sendToSrc:Unit) 和 (sendToDst:Unit) ）。可以將 sendMsg 視作 map-reduce 中的 map 函數。\n",
    "\n",
    "* 而使用者自定義的 mergeMsg 函數接受兩個指定的訊息到相同的頂點並產生一個訊息，可以將 mergeMsg 視作 map-reduce 中的 reduce 函數。aggregateMessages⇒Unit,(A,A)⇒A,TripletFields)(ClassTag[A]):VertexRDD[A]) 運算子會回傳一個包含匯集訊息（Msg型別）到指定的每一個頂點的 VertexRDD[Msg]。沒有接收到訊息的頂點不會包含在回傳的 VertexRDD 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,(Amber,2000000))\n",
      "(11,(Amber,2000000))\n",
      "(1,(Amber,2000000))\n",
      "(6,(Amber,2000000))\n",
      "(3,(Amber,2000000))\n",
      "(7,(Amber,2000000))\n",
      "(9,(RC,5000000))\n",
      "(8,(Amber,2000000))\n",
      "(10,(Amber,2000000))\n",
      "(2,(Amber,2000000))\n",
      "\n",
      "Amber is the follower of Miles.\n",
      "Amber is the follower of Scala.\n",
      "Amber is the follower of RC.\n",
      "Amber is the follower of Bgg.\n",
      "Amber is the follower of Roger.\n",
      "Amber is the follower of Alex.\n",
      "RC is the follower of Cathay.\n",
      "Amber is the follower of Vickie.\n",
      "Java does not have any followers.\n",
      "Amber is the follower of Python.\n",
      "Amber does not have any followers.\n",
      "Amber is the follower of TH.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmaxSalaryFollower\u001b[39m: \u001b[32mVertexRDD\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = VertexRDDImpl[322] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val maxSalaryFollower: VertexRDD[(String,Int)] = userGraph.aggregateMessages[(String, Int)](\n",
    "  // 將來源節點的屬性發送給目標節點，map 過程\n",
    "  triplet => {\n",
    "      triplet.sendToDst(triplet.srcAttr.name, triplet.srcAttr.salary)\n",
    "  },\n",
    "  // 得到薪水最大的 follower，reduce 過程\n",
    "  (a, b) => if (a._2 > b._2) a else b\n",
    ")\n",
    "\n",
    "maxSalaryFollower.collect.foreach(println(_))\n",
    "println\n",
    "\n",
    "userGraph.vertices.leftJoin(maxSalaryFollower) {\n",
    "  (id, user, optMaxSalaryFollower) => optMaxSalaryFollower match {\n",
    "                                                                    case None => s\"${user.name} does not have any followers.\"\n",
    "                                                                    case Some((name, salary)) => s\"${name} is the follower of ${user.name}.\"\n",
    "                                                                  }\n",
    "}.collect.foreach{ case (id, str) => println(str) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
