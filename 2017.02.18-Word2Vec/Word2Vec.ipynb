{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 gensim 套件\n",
    "pip install gensim\n",
    "\n",
    "### 相依的其他套件\n",
    "##### NumPy\n",
    "##### SciPy\n",
    "##### Cython\n",
    "在進行模型訓練的時候，如果沒有安裝Cython，便只能使用單核，執行速度較慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 jieba 套件\n",
    "pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 資料來源：中文維基百科\n",
    "https://dumps.wikimedia.org/zhwiki/20170201/\n",
    "\n",
    "檔名：zhwiki-20170201-pages-articles.xml.bz2\n",
    "\n",
    "但此處只取前 5000 篇文章作為範例檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 採用 jieba 進行中文斷詞\n",
    "結巴中文分詞支持的三種分詞模式包括：\n",
    "### 1. 精確模式：將句子最精確地切開，適合文本分析。\n",
    "寫法：words = jieba.cut(content, cut_all=False)\n",
    "### 2.全模式：把句子中所有可以成詞的詞語都掃描出來，速度快。\n",
    "寫法：words = jieba.cut(content, cut_all=True)\n",
    "### 3.搜索引勤模式：在精確模式的基礎上對長詞再次切分，提高召回率，適合用於搜尋引擎分詞。\n",
    "寫法：jieba.cut_for_search(Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import logging\n",
    "import multiprocessing\n",
    "import jieba\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence, Text8Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment(input_path, output_path):\n",
    "    \"\"\"\n",
    "    利用結巴套件斷字，使用預設詞庫（最基本的用法）\n",
    "    \"\"\"    \n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    \n",
    "    # jieba custom setting.\n",
    "    jieba.load_userdict('userdict_modified.txt')\n",
    "\n",
    "    # load stopwords set\n",
    "    stopwordset = set()\n",
    "    with io.open('stop_words.txt', 'r', encoding='utf-8') as sw:\n",
    "        for line in sw:\n",
    "            stopwordset.add(line.strip('\\n'))\n",
    "\n",
    "    output = open(output_path,'w')\n",
    "    texts_num = 0 \n",
    "    \n",
    "    with open(input_path,'r') as content :\n",
    "        for line in content:\n",
    "            words = jieba.cut(line, cut_all=False)  # 精確模式\n",
    "            for word in words:\n",
    "                if word not in stopwordset:\n",
    "                    output.write(word.encode('utf-8') +' ')                        \n",
    "            texts_num += 1\n",
    "            if texts_num % 500 == 0:\n",
    "                logging.info(\"已完成前 %d 行的斷詞\" % texts_num)\n",
    "    \n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment('datasource/wiki_zh_tw_part.txt', 'datasource/wiki_seg_part.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用 gensim 套件\n",
    "\n",
    "Gensim, programmed by Radim Řehůřek, is an open source package suitable ",
    "to analyze large textual collections by the usage of parallel distributable online algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 訓練、儲存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_word2vec(corpus_path, savePath):\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    \n",
    "    corpus = LineSentence(corpus_path) # 採用內建函式讀入 corpus\n",
    "    \n",
    "    num_features = 250 # 詞向量的維度（即：隱藏層的神經元個數）\n",
    "    window_size = 5 # 考慮前後文的範圍\n",
    "    min_count = 5 # 若某字彙出現的次數小於 min_count，那它就不會被視為訓練對象，會被丟棄\n",
    "    sg_type = 0 # sg=0，CBOW  # sg=1，skip-gram\n",
    "    \n",
    "    model = Word2Vec(corpus, size=num_features, sg=sg_type, window=window_size, min_count=min_count, workers=multiprocessing.cpu_count())    \n",
    "    \n",
    "    # 儲存模型\n",
    "    model.save(savePath+'word2vec_model') # gensim 的 model 格式\n",
    "    model.save_word2vec_format(savePath+'word2vec_model_vec.txt', binary=False) # 原生 C 的 model 格式，以非二進制方式儲存，方便人去查看\n",
    "    model.save_word2vec_format(savePath+'word2vec_model_vec.bin', binary=True) # 原生 C 的 model 格式，以二進制方式儲存，提高i/o效能\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_word2vec('datasource/wiki_seg_part.txt', 'model_result/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############\n",
    "## 載入模型 ##\n",
    "#############\n",
    "\n",
    "## gensim 的 model 格式\n",
    "#model_gensim = Word2Vec.load('model_result/word2vec_model')\n",
    "\n",
    "## 原生 C 的 model 格式\n",
    "#model_c_txt = Word2Vec.load_word2vec_format('model_result/word2vec_model_vec.txt', binary=False)\n",
    "#model_c_bin = Word2Vec.load_word2vec_format('model_result/word2vec_model_vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ps(result):  \n",
    "    if result:\n",
    "        for e in result:\n",
    "            print e[0], e[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) model 中的所有詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in model.wv.vocab:\n",
    "    print key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 特定詞彙的詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw NumPy vector of a word\n",
    "model[u'情人']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 找出與特定詞彙最相似的其他詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-18 14:52:55,246 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "女孩 0.917469084263\n",
      "媽媽 0.91675645113\n",
      "續集 0.912169754505\n",
      "張學友 0.911907672882\n",
      "客串 0.905912518501\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(u'情人', topn=5)\n",
    "ps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上海 0.867828786373\n",
      "天津 0.815129578114\n",
      "南京 0.760588943958\n",
      "重慶 0.756330907345\n",
      "西安 0.734520614147\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(u'北京', topn=5)\n",
    "ps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新竹 0.861851036549\n",
      "捷運 0.854273676872\n",
      "戲院 0.845746219158\n",
      "高雄市 0.841543316841\n",
      "嘉義 0.838007032871\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(u'高雄', topn=5)\n",
    "ps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frederick 0.955409049988\n",
      "tudor 0.949015796185\n",
      "bach 0.948603689671\n",
      "philip 0.948344528675\n",
      "maurice 0.947911918163\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)  # woman+king-man=?\n",
    "ps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "君主 0.805771589279\n",
      "統治者 0.783081352711\n",
      "國王 0.770947754383\n",
      "教宗 0.763281166553\n",
      "皇位 0.762493312359\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=[u'女', u'皇帝'], negative=[u'男'], topn=5)   # 女+皇帝-男=?\n",
    "ps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "廟號 0.79917371273\n",
      "君主 0.787366986275\n",
      "開國 0.785382032394\n",
      "尊號 0.784314870834\n",
      "皇位 0.782575488091\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=[u'女人', u'皇帝'], negative=[u'男人'], topn=5)   # 女人+皇帝-男人=?\n",
    "ps(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 計算兩個詞彙的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961160928823\n"
     ]
    }
   ],
   "source": [
    "print model.similarity(u\"男人\", u\"女人\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 從一堆詞彙裡面找到不匹配的詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中心\n"
     ]
    }
   ],
   "source": [
    "print model.doesnt_match(u\"早餐 晚餐 午餐 中心\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上海\n"
     ]
    }
   ],
   "source": [
    "print model.doesnt_match(u\"高雄 嘉義 上海\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 更新模型：訓練新的語料 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 載入已經訓練好的模型\n",
    "model_gensim = Word2Vec.load('model_result/word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-18 14:53:40,457 : WARNING : direct access to vocab will not be supported in future gensim releases, please use model.wv.vocab\n",
      "2017-02-18 14:53:40,459 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情詩 0.924734652042\n",
      "豬八戒 0.921241462231\n",
      "梟雄 0.920531213284\n",
      "二十首 0.919621646404\n",
      "離別 0.919123828411\n"
     ]
    }
   ],
   "source": [
    "keyword = u'蝶戀花'\n",
    "\n",
    "if keyword in model_gensim.vocab:\n",
    "    result = model_gensim.most_similar(keyword, topn=5)\n",
    "    ps(result)\n",
    "else:\n",
    "    print keyword + u\"不在字典中！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 新的語料\n",
    "segment('datasource/news.txt', 'datasource/news_seg.txt')\n",
    "new_corpus = LineSentence('datasource/news_seg.txt')\n",
    "\n",
    "# 更新模型：訓練新的語料\n",
    "model_gensim.train(new_corpus)\n",
    "\n",
    "# 儲存更新後的模型\n",
    "model_gensim.save('model_result/word2vec_model_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-18 14:53:57,690 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "旅行社 0.887470602989\n",
      "顧城 0.831960201263\n",
      "郭德潔 0.818841576576\n",
      "立群 0.812965035439\n",
      "保外 0.812554180622\n"
     ]
    }
   ],
   "source": [
    "keyword = u'蝶戀花'\n",
    "if keyword in model_gensim.wv.vocab:\n",
    "    result = model_gensim.most_similar(keyword, topn=5)\n",
    "    ps(result)\n",
    "else:\n",
    "    print keyword + u\"不在字典中！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "女孩 0.917469084263\n",
      "媽媽 0.91675645113\n",
      "續集 0.912169754505\n",
      "張學友 0.911907672882\n",
      "客串 0.905912518501\n"
     ]
    }
   ],
   "source": [
    "result = model_gensim.most_similar(u'情人', topn=5)\n",
    "ps(result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
