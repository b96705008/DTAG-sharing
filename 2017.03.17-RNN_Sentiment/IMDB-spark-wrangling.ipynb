{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# dataset url: 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'local[*]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "TOKEN_REGEX = re.compile(r'[A-Za-z]+|[!?.:,()]')\n",
    "\n",
    "def tokenize(text):\n",
    "    data = TOKEN_REGEX.findall(text)\n",
    "    return [x.lower() for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i', u'love', u'you', u'!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"I love you!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pos_rdd = sc.textFile('aclimdb/train/pos/*')\n",
    "train_neg_rdd = sc.textFile('aclimdb/train/neg/*')\n",
    "test_pos_rdd = sc.textFile('aclimdb/test/pos/*')\n",
    "test_neg_rdd = sc.textFile('aclimdb/test/neg/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "train_pos_df = train_pos_rdd.map(lambda l: Row(text=tokenize(l), sentiment=1)).toDF()\n",
    "train_neg_df = train_neg_rdd.map(lambda l: Row(text=tokenize(l), sentiment=0)).toDF()\n",
    "train_df = train_pos_df.union(train_neg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words_n = 5000\n",
    "\n",
    "top_words = train_df.rdd \\\n",
    "    .flatMap(lambda r: r.text) \\\n",
    "    .map(lambda w: (w, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .takeOrdered(top_words_n - 1, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabs = ['<UNK>'] + [w for w, _ in top_words[:top_words_n-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_index = 1\n",
    "word_indices = {w: (i+start_index) for i, w in enumerate(vocabs)}\n",
    "index_words = {(i+start_index): w for i, w in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'<UNK>'), (2, u'the'), (3, u'.'), (4, u','), (5, u'and')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_words.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "b_word_indices = sc.broadcast(word_indices)\n",
    "\n",
    "def encode_words(words):\n",
    "    return [b_word_indices.value.get(w, 1) for w in words]\n",
    "\n",
    "encode_words_udf = udf(encode_words, ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_train_df = train_df.withColumn('indices', encode_words_udf(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|sentiment|                text|             indices|\n",
      "+---------+--------------------+--------------------+\n",
      "|        1|[bromwell, high, ...|[1, 316, 9, 6, 10...|\n",
      "|        1|[homelessness, (,...|[1, 25, 48, 1, 18...|\n",
      "|        1|[brilliant, over,...|[527, 127, 121, 4...|\n",
      "|        1|[this, is, easily...|[14, 9, 701, 2, 9...|\n",
      "|        1|[this, is, not, t...|[14, 9, 29, 2, 78...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: long (nullable = true)\n",
      " |-- text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- indices: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_reviews = encoded_train_df.select('indices', 'sentiment').rdd \\\n",
    "    .map(lambda r: {'features': [r.indices], 'labels': [r.sentiment]}) \\\n",
    "    .reduce(lambda a, b: {f: a[f] + b[f] for f in ['features', 'labels']}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "train_reviews['features'] = sequence.pad_sequences(train_reviews['features'], maxlen=500)\n",
    "train_reviews['labels'] = np.array(train_reviews['labels'])\n",
    "\n",
    "indices = np.random.permutation(25000)\n",
    "train_reviews['features'] = train_reviews['features'][indices]\n",
    "train_reviews['labels'] = train_reviews['labels'][indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Keras Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 500, 32)       160032      embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 100)           53200       embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             101         lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 213,333\n",
      "Trainable params: 213,333\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5001, 32, input_length=500))\n",
    "model.add(LSTM(output_dim=100, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid')) # positive or negative -> 1 or 0\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 538s - loss: 0.5499 - acc: 0.7106   \n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 536s - loss: 0.3162 - acc: 0.8692   \n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 545s - loss: 0.2576 - acc: 0.9002   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123c0fd10>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_reviews['features'] , train_reviews['labels'], nb_epoch=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pos_df = test_pos_rdd.map(lambda l: Row(text=tokenize(l), sentiment=1)).toDF()\n",
    "test_neg_df = test_neg_rdd.map(lambda l: Row(text=tokenize(l), sentiment=0)).toDF()\n",
    "test_df = test_pos_df.union(test_neg_df)\n",
    "\n",
    "encoded_test_df = test_df.withColumn('indices', encode_words_udf(col('text')))\n",
    "test_reviews = encoded_test_df.select('indices', 'sentiment').rdd \\\n",
    "    .map(lambda r: {'features': [r.indices], 'labels': [r.sentiment]}) \\\n",
    "    .reduce(lambda a, b: {f: a[f] + b[f] for f in ['features', 'labels']}) \n",
    "\n",
    "test_reviews['features'] = sequence.pad_sequences(test_reviews['features'], maxlen=500)\n",
    "test_reviews['labels'] = np.array(test_reviews['labels'])\n",
    "\n",
    "indices = np.random.permutation(25000)\n",
    "test_reviews['features'] = test_reviews['features'][indices]\n",
    "test_reviews['labels'] = test_reviews['labels'][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 135s   \n",
      "Accuracy: 86.43%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_reviews['features'], test_reviews['labels'], verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train more on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_batches(reviews, batch_size): \n",
    "    while True:\n",
    "        indices = np.random.permutation(review_size)\n",
    "        features = reviews['features'][indices]\n",
    "        labels = reviews['labels'][indices]\n",
    "        n_batch = review_size // batch_size\n",
    "        offset = 0\n",
    "        for i in range(n_batch):\n",
    "            yield features[offset:offset+batch_size], labels[offset:offset+batch_size]\n",
    "            offset += batch_size\n",
    "\n",
    "next_reviews = review_batches(test_reviews, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0,   0,   0, ...,  15,  57,   3],\n",
       "        [  0,   0,   0, ...,  79,   1,   3],\n",
       "        [ 50,  96,   4, ...,  15, 198,   3],\n",
       "        ..., \n",
       "        [  0,   0,   0, ..., 179,  64,   3],\n",
       "        [  0,   0,   0, ...,   7, 681,   3],\n",
       "        [  0,   0,   0, ..., 345,   1,   3]], dtype=int32),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(next_reviews)\n",
    "X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540145 0.78125\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.train_on_batch(X_batch, y_batch)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522179 0.8125\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.test_on_batch(X_batch, y_batch)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    encoded_words = [word_indices.get(w, 1) for w in tokenize(sentence)]\n",
    "    test_features = sequence.pad_sequences(np.array(encoded_words).reshape(1, -1), maxlen=500)\n",
    "    logit = model.predict_on_batch(test_features)[0, 0]\n",
    "    senti = 'positive' if logit > 0.5 else 'negative'\n",
    "    return (logit, senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.76548088, u'positive')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment('I love it! I really like this movie.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47480059, u'negative')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment('It is a bad movie! I do not like it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
