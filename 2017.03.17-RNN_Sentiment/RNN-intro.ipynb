{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNN cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-structure.png\" alt=\"RNN structure\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "max_steps = 2\n",
    "n_inputs = 3\n",
    "\n",
    "# data shape: batch_size X sequence_length X feature_num\n",
    "X = tf.placeholder(tf.float32, [None, max_steps, n_inputs])\n",
    "\n",
    "# Basic RNN\n",
    "n_neurons = 5  # hidden size for rnn cell\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons) # X(t)*Wx + y(t-1)*Wy = y(t) \n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[[-0.94336641  0.78830135  0.93238342 -0.53071505 -0.37779272]\n",
      "  [-0.99999994  0.99999964  1.         -0.97666121 -0.94991612]]\n",
      "\n",
      " [[-0.9999727   0.99968761  0.9999907  -0.91765964 -0.85683709]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-1.          0.99999964  1.         -0.98804462 -0.97401565]\n",
      "  [-0.99973381  0.99932456  0.99999863 -0.84873462 -0.80149025]]\n",
      "\n",
      " [[-0.86643529  0.99133348  0.99977899  0.47188064  0.96711951]\n",
      "  [-0.95520151  0.97891372  0.99928331  0.10864748  0.01988852]]]\n",
      "\n",
      "states:\n",
      "[[-0.99999994  0.99999964  1.         -0.97666121 -0.94991612]\n",
      " [-0.9999727   0.99968761  0.9999907  -0.91765964 -0.85683709]\n",
      " [-0.99973381  0.99932456  0.99999863 -0.84873462 -0.80149025]\n",
      " [-0.95520151  0.97891372  0.99928331  0.10864748  0.01988852]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([\n",
    "         # t = 0     t = 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 0, length = 2\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 1, length = 1\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 2, length = 2\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 3, length = 2\n",
    "    ])\n",
    "\n",
    "X_length = [2,1,2,2]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: X_length})\n",
    "    print('outputs:')\n",
    "    print(outputs_val)\n",
    "    print('\\nstates:')\n",
    "    print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-types.png\" alt=\"RNN types\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/LSTM.png\" alt=\"LSTM\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-deep.png\" alt=\"Deep RNN\" style=\"width: 600px;\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "max_steps = 2\n",
    "n_inputs = 3\n",
    "\n",
    "# data shape: batch_size X sequence_length X feature_num\n",
    "X = tf.placeholder(tf.float32, [None, max_steps, n_inputs])\n",
    "\n",
    "# Basic RNN\n",
    "n_neurons = 5\n",
    "n_layers = 3\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell([basic_cell] * n_layers)\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[[-0.25792614 -0.15808602  0.11610406 -0.34532174 -0.17429137]\n",
      "  [-0.66740745  0.08121295 -0.29551756 -0.03799359 -0.38327646]]\n",
      "\n",
      " [[-0.32111779 -0.17445439  0.10995026 -0.35037693 -0.16939144]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.34911358 -0.19412838  0.1064423  -0.32386175 -0.15464006]\n",
      "  [-0.67758453  0.31614462 -0.38080788  0.09814353 -0.23457474]]\n",
      "\n",
      " [[ 0.22410728  0.25423193 -0.19750072  0.41633067  0.12349871]\n",
      "  [ 0.18127856 -0.38801974  0.50288171 -0.21824214 -0.50736445]]]\n",
      "\n",
      "states:\n",
      "layer 1\n",
      "[[ 0.7219075  -0.09534707 -0.98359156 -0.99862498 -0.86546892]\n",
      " [ 0.89839154  0.49845704 -0.9963544  -0.98187983  0.26582101]\n",
      " [ 0.60942096 -0.27353281 -0.5767386  -0.98241305 -0.84704751]\n",
      " [-0.92024708  0.69848144 -0.79852301  0.4837833  -0.08642693]]\n",
      "layer 2\n",
      "[[-0.84737265  0.46746391 -0.52890605  0.35808447 -0.3022635 ]\n",
      " [-0.60922343  0.16847374  0.15551859  0.78700322 -0.2671763 ]\n",
      " [-0.83922887  0.47185495 -0.48851815 -0.09702769 -0.39904481]\n",
      " [ 0.79286218 -0.00910623 -0.34527382  0.50873607  0.77845544]]\n",
      "layer 3\n",
      "[[-0.66740745  0.08121295 -0.29551756 -0.03799359 -0.38327646]\n",
      " [-0.32111779 -0.17445439  0.10995026 -0.35037693 -0.16939144]\n",
      " [-0.67758453  0.31614462 -0.38080788  0.09814353 -0.23457474]\n",
      " [ 0.18127856 -0.38801974  0.50288171 -0.21824214 -0.50736445]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([\n",
    "         # t = 0     t = 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 0, length = 2\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 1, length = 1\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 2, length = 2\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 3, length = 2\n",
    "    ])\n",
    "\n",
    "X_length = [2,1,2,2]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: X_length})\n",
    "    print('outputs:')\n",
    "    print(outputs_val)\n",
    "    print('\\nstates:')\n",
    "    for i, s in enumerate(states_val):\n",
    "        print('layer {}'.format(i + 1))\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding before RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process sequence with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4 2 3]\n",
      " [0 0 0 1 2]\n",
      " [0 4 5 2 1]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    [1, 2, 4, 2, 3], # 我 非常 愛 你 唷\n",
    "    [0, 1, 2], \n",
    "    [4, 5, 2, 1],\n",
    "    [5, 2, 1, 3, 4, 1, 2, 3, 4, 5]\n",
    "]\n",
    "\n",
    "max_length = 5\n",
    "pad_texts = sequence.pad_sequences(texts, maxlen=5)\n",
    "print(pad_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer (keras as interface to tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.04115858 -0.00087099  0.03553173]\n",
      "  [-0.00483301 -0.01721189  0.03400842]\n",
      "  [-0.00439917  0.01894731 -0.04771699]\n",
      "  [-0.00483301 -0.01721189  0.03400842]\n",
      "  [ 0.01789529 -0.0384722   0.03360324]]\n",
      "\n",
      " [[ 0.03390614  0.02066951  0.01423012]\n",
      "  [ 0.03390614  0.02066951  0.01423012]\n",
      "  [ 0.03390614  0.02066951  0.01423012]\n",
      "  [-0.04115858 -0.00087099  0.03553173]\n",
      "  [-0.00483301 -0.01721189  0.03400842]]\n",
      "\n",
      " [[ 0.03390614  0.02066951  0.01423012]\n",
      "  [-0.00439917  0.01894731 -0.04771699]\n",
      "  [ 0.03371974  0.02353113  0.00150312]\n",
      "  [-0.00483301 -0.01721189  0.03400842]\n",
      "  [-0.04115858 -0.00087099  0.03553173]]\n",
      "\n",
      " [[-0.04115858 -0.00087099  0.03553173]\n",
      "  [-0.00483301 -0.01721189  0.03400842]\n",
      "  [ 0.01789529 -0.0384722   0.03360324]\n",
      "  [-0.00439917  0.01894731 -0.04771699]\n",
      "  [ 0.03371974  0.02353113  0.00150312]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, max_length])\n",
    "\n",
    "top_words = 6 # 0 ~ 5\n",
    "embedding_length = 3\n",
    "embedding = Embedding(input_dim=top_words, output_dim=embedding_length, input_length=max_length)(X)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(embedding.eval(feed_dict={X: pad_texts}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding + LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[[  2.27748300e-03   2.54794490e-03]\n",
      "  [ -6.72289636e-03   2.12552119e-03]\n",
      "  [ -5.15798200e-03   2.57817283e-03]\n",
      "  [ -1.18720494e-02   1.75152568e-03]\n",
      "  [ -1.17209079e-02   2.15285574e-03]]\n",
      "\n",
      " [[ -7.16912677e-04  -4.45036776e-03]\n",
      "  [ -5.85651200e-04  -8.36673286e-03]\n",
      "  [  4.92734434e-05  -1.17795616e-02]\n",
      "  [  3.92194884e-03  -7.55762029e-03]\n",
      "  [ -4.20305226e-03  -6.66038040e-03]]\n",
      "\n",
      " [[ -7.16912677e-04  -4.45036776e-03]\n",
      "  [ -2.09720354e-04  -2.76012183e-03]\n",
      "  [  4.19360040e-05  -5.89074241e-03]\n",
      "  [ -7.10867392e-03  -5.33945905e-03]\n",
      "  [ -1.77819841e-03  -2.39658100e-03]]\n",
      "\n",
      " [[  2.27748300e-03   2.54794490e-03]\n",
      "  [ -6.72289636e-03   2.12552119e-03]\n",
      "  [ -8.27405322e-03   2.74330750e-03]\n",
      "  [ -6.33774092e-03   3.04499455e-03]\n",
      "  [ -4.98534460e-03  -1.12100574e-03]]]\n",
      "\n",
      "states:\n",
      "LSTMStateTuple(c=array([[-0.02339812,  0.00432264],\n",
      "       [-0.00834949, -0.01318919],\n",
      "       [-0.00356107, -0.00483211],\n",
      "       [-0.0098818 , -0.00223147]], dtype=float32), h=array([[-0.01172091,  0.00215286],\n",
      "       [-0.00420305, -0.00666038],\n",
      "       [-0.0017782 , -0.00239658],\n",
      "       [-0.00498534, -0.00112101]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, max_length])\n",
    "\n",
    "# Embedding\n",
    "top_words = 6 # 0 ~ 5\n",
    "embedding_length = 3\n",
    "embedding = Embedding(input_dim=top_words, output_dim=embedding_length, input_length=max_length)(X)\n",
    "\n",
    "# LSTM\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=2)\n",
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, embedding, dtype=tf.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: pad_texts})\n",
    "    print('outputs:')\n",
    "    print(outputs_val)\n",
    "    print('\\nstates:')\n",
    "    print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace with Keras LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.0092869   0.00178546]\n",
      "  [-0.02605121  0.00459695]\n",
      "  [-0.02878794  0.00521053]\n",
      "  [-0.04146672  0.00858775]\n",
      "  [-0.0255339   0.00482388]]\n",
      "\n",
      " [[-0.00984028  0.00317693]\n",
      "  [-0.01728653  0.00655342]\n",
      "  [-0.02271022  0.0100574 ]\n",
      "  [-0.02586466  0.01219606]\n",
      "  [-0.0374227   0.0150606 ]]\n",
      "\n",
      " [[-0.00984028  0.00317693]\n",
      "  [-0.01579443  0.00325947]\n",
      "  [-0.02110537  0.00349698]\n",
      "  [-0.03553843  0.00662705]\n",
      "  [-0.03701945  0.00943947]]\n",
      "\n",
      " [[-0.0092869   0.00178546]\n",
      "  [-0.02605121  0.00459695]\n",
      "  [-0.01381799  0.00033406]\n",
      "  [-0.0200562   0.00070674]\n",
      "  [-0.02532266  0.00114754]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, max_length])\n",
    "\n",
    "# Embedding\n",
    "top_words = 6 # 0 ~ 5\n",
    "embedding_length = 3\n",
    "embedding = Embedding(input_dim=top_words, output_dim=embedding_length, input_length=max_length)(X)\n",
    "\n",
    "# LSTM\n",
    "outputs = LSTM(2, return_sequences=True)(embedding)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = sess.run(outputs, feed_dict={X: pad_texts})\n",
    "    print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
