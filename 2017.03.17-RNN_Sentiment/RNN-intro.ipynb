{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNN cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-structure.png\" alt=\"RNN structure\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "max_steps = 2\n",
    "n_inputs = 3\n",
    "\n",
    "# data shape: batch_size X sequence_length X feature_num\n",
    "X = tf.placeholder(tf.float32, [None, max_steps, n_inputs])\n",
    "\n",
    "# Basic RNN\n",
    "n_neurons = 5  # hidden size for rnn cell\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons) # X(t)*Wx + y(t-1)*Wy = y(t) \n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[[ 0.07388831  0.83327669 -0.92938942  0.65999997  0.32705325]\n",
      "  [-0.99995208  0.99999964 -0.99987948 -0.90367883  0.34513646]]\n",
      "\n",
      " [[-0.91396397  0.99929625 -0.99860328  0.64561605  0.5721463 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.99652094  0.99999738 -0.99997348  0.63075882  0.74511898]\n",
      "  [-0.99873692  0.99980426 -0.9988488  -0.86127239  0.34120306]]\n",
      "\n",
      " [[-0.99899191  0.71895832  0.99938679 -0.99996424 -0.99846786]\n",
      "  [-0.96630585  0.91309631  0.11886316  0.46950158  0.32660544]]]\n",
      "\n",
      "states:\n",
      "[[-0.99995208  0.99999964 -0.99987948 -0.90367883  0.34513646]\n",
      " [-0.91396397  0.99929625 -0.99860328  0.64561605  0.5721463 ]\n",
      " [-0.99873692  0.99980426 -0.9988488  -0.86127239  0.34120306]\n",
      " [-0.96630585  0.91309631  0.11886316  0.46950158  0.32660544]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([\n",
    "         # t = 0     t = 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 0, length = 2\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 1, length = 1\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 2, length = 2\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 3, length = 2\n",
    "    ])\n",
    "\n",
    "X_length = [2,1,2,2]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: X_length})\n",
    "    print('outputs:')\n",
    "    print(outputs_val)\n",
    "    print('\\nstates:')\n",
    "    print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-types.png\" alt=\"RNN types\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/LSTM.png\" alt=\"LSTM\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RNN-deep.png\" alt=\"Deep RNN\" style=\"width: 600px;\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "max_steps = 2\n",
    "n_inputs = 3\n",
    "\n",
    "# data shape: batch_size X sequence_length X feature_num\n",
    "X = tf.placeholder(tf.float32, [None, max_steps, n_inputs])\n",
    "\n",
    "# Basic RNN\n",
    "n_neurons = 5\n",
    "n_layers = 3\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell([basic_cell] * n_layers)\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[[-0.30183983 -0.53327268 -0.17626247  0.18664394 -0.0069315 ]\n",
      "  [ 0.13133709 -0.7593841   0.10228386  0.76015329  0.03787287]]\n",
      "\n",
      " [[-0.40445489 -0.52822912 -0.15684663  0.39030898  0.05710426]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.42082024 -0.50986516 -0.16582783  0.42077854  0.0718665 ]\n",
      "  [ 0.2561976  -0.69520563  0.40204772  0.78219736 -0.0561308 ]]\n",
      "\n",
      " [[ 0.27107078 -0.07842363  0.33445096  0.31843457  0.01669742]\n",
      "  [ 0.82530582 -0.15954629  0.46029335  0.63888782 -0.07108143]]]\n",
      "\n",
      "states:\n",
      "layer 1\n",
      "[[-1.          0.99747026  0.93127561  0.5574705   0.94813067]\n",
      " [-0.99987203  0.87718564  0.98404205 -0.73622203  0.78220993]\n",
      " [-0.99997163  0.89926952 -0.37906125  0.67388755  0.76403129]\n",
      " [-0.96757096 -0.12766157  0.49969807  0.96959639  0.88902229]]\n",
      "layer 2\n",
      "[[ 0.59466916 -0.54594117  0.81721985  0.78625739  0.89290899]\n",
      " [ 0.70465624 -0.42469725  0.31548288 -0.20719554  0.82733977]\n",
      " [ 0.29520756 -0.09792763  0.88097161  0.89828491  0.77829367]\n",
      " [-0.47391507  0.48294088  0.61303627  0.76504618 -0.47434625]]\n",
      "layer 3\n",
      "[[ 0.13133709 -0.7593841   0.10228386  0.76015329  0.03787287]\n",
      " [-0.40445489 -0.52822912 -0.15684663  0.39030898  0.05710426]\n",
      " [ 0.2561976  -0.69520563  0.40204772  0.78219736 -0.0561308 ]\n",
      " [ 0.82530582 -0.15954629  0.46029335  0.63888782 -0.07108143]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([\n",
    "         # t = 0     t = 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 0, length = 2\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 1, length = 1\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 2, length = 2\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 3, length = 2\n",
    "    ])\n",
    "\n",
    "X_length = [2,1,2,2]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: X_length})\n",
    "    print('outputs:')\n",
    "    print(outputs_val)\n",
    "    print('\\nstates:')\n",
    "    for i, s in enumerate(states_val):\n",
    "        print('layer {}'.format(i + 1))\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding before RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process sequence with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4 2 3]\n",
      " [0 0 0 1 2]\n",
      " [0 4 5 2 1]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    [1, 2, 4, 2, 3], # 我 非常 愛 你 唷\n",
    "    [0, 1, 2], \n",
    "    [4, 5, 2, 1],\n",
    "    [5, 2, 1, 3, 4, 1, 2, 3, 4, 5]\n",
    "]\n",
    "\n",
    "max_length = 5\n",
    "pad_texts = sequence.pad_sequences(texts, maxlen=5)\n",
    "print(pad_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer (keras as interface to tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.02795983  0.02821353  0.04689256]\n",
      "  [-0.04656286  0.0403927   0.03845784]\n",
      "  [-0.00709755 -0.03114094 -0.00675856]\n",
      "  [-0.04656286  0.0403927   0.03845784]\n",
      "  [ 0.02828236  0.0426243  -0.00267712]]\n",
      "\n",
      " [[ 0.01448289  0.02166584  0.00406395]\n",
      "  [ 0.01448289  0.02166584  0.00406395]\n",
      "  [ 0.01448289  0.02166584  0.00406395]\n",
      "  [ 0.02795983  0.02821353  0.04689256]\n",
      "  [-0.04656286  0.0403927   0.03845784]]\n",
      "\n",
      " [[ 0.01448289  0.02166584  0.00406395]\n",
      "  [-0.00709755 -0.03114094 -0.00675856]\n",
      "  [ 0.00649448 -0.01626713 -0.01955664]\n",
      "  [-0.04656286  0.0403927   0.03845784]\n",
      "  [ 0.02795983  0.02821353  0.04689256]]\n",
      "\n",
      " [[ 0.02795983  0.02821353  0.04689256]\n",
      "  [-0.04656286  0.0403927   0.03845784]\n",
      "  [ 0.02828236  0.0426243  -0.00267712]\n",
      "  [-0.00709755 -0.03114094 -0.00675856]\n",
      "  [ 0.00649448 -0.01626713 -0.01955664]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, max_length])\n",
    "\n",
    "top_words = 6 # 0 ~ 5\n",
    "embedding_length = 3\n",
    "embedding = Embedding(input_dim=top_words, output_dim=embedding_length, input_length=max_length)(X)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(embedding.eval(feed_dict={X: pad_texts}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding + LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "[[[  5.23487525e-03   2.93326052e-03]\n",
      "  [ -3.99231398e-03  -2.89404648e-03]\n",
      "  [ -5.82309719e-03  -3.70874559e-03]\n",
      "  [ -9.44848359e-03  -7.16878520e-03]\n",
      "  [ -3.46902059e-03  -5.17792813e-03]]\n",
      "\n",
      " [[  4.40151477e-03   7.06857885e-04]\n",
      "  [  6.83350209e-03   7.70605111e-04]\n",
      "  [  8.21824092e-03   5.26803546e-04]\n",
      "  [  9.87391826e-03   2.35701539e-03]\n",
      "  [ -1.32134371e-03  -3.91992414e-03]]\n",
      "\n",
      " [[  4.40151477e-03   7.06857885e-04]\n",
      "  [ -1.54581759e-03  -1.64780370e-03]\n",
      "  [ -1.19421538e-03  -6.20696228e-05]\n",
      "  [ -7.24426657e-03  -4.63420339e-03]\n",
      "  [  1.64141145e-03  -2.07956109e-04]]\n",
      "\n",
      " [[  5.23487525e-03   2.93326052e-03]\n",
      "  [ -3.99231398e-03  -2.89404648e-03]\n",
      "  [ -8.89721443e-04  -2.15966930e-03]\n",
      "  [ -4.16075531e-03  -3.43416282e-03]\n",
      "  [ -2.48068268e-03  -1.28060323e-03]]]\n",
      "\n",
      "states:\n",
      "LSTMStateTuple(c=array([[-0.0069551 , -0.01032648],\n",
      "       [-0.00265441, -0.0079504 ],\n",
      "       [ 0.00327387, -0.00041221],\n",
      "       [-0.00494373, -0.00254638]], dtype=float32), h=array([[-0.00346902, -0.00517793],\n",
      "       [-0.00132134, -0.00391992],\n",
      "       [ 0.00164141, -0.00020796],\n",
      "       [-0.00248068, -0.0012806 ]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, max_length])\n",
    "\n",
    "# Embedding\n",
    "top_words = 6 # 0 ~ 5\n",
    "embedding_length = 3\n",
    "embedding = Embedding(input_dim=top_words, output_dim=embedding_length, input_length=max_length)(X)\n",
    "\n",
    "# LSTM\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=2)\n",
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, embedding, dtype=tf.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: pad_texts})\n",
    "    print('outputs:')\n",
    "    print(outputs_val)\n",
    "    print('\\nstates:')\n",
    "    print(states_val) # c: states_val[0], long-term, h: states_val[1], short-term (result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace with Keras LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.00398481 -0.00284151]\n",
      "  [-0.01287368 -0.0047118 ]\n",
      "  [-0.00586984 -0.00344549]\n",
      "  [-0.01399477 -0.00500292]\n",
      "  [-0.00138086 -0.00590383]]\n",
      "\n",
      " [[ 0.00885494  0.00543   ]\n",
      "  [ 0.01414005  0.00956309]\n",
      "  [ 0.01745504  0.01291808]\n",
      "  [ 0.00738959  0.00708744]\n",
      "  [-0.00542119  0.00340092]]\n",
      "\n",
      " [[ 0.00885494  0.00543   ]\n",
      "  [ 0.00648394  0.00357731]\n",
      "  [ 0.0017614   0.01603111]\n",
      "  [-0.00642674  0.01283678]\n",
      "  [-0.00457685  0.01093406]]\n",
      "\n",
      " [[-0.00398481 -0.00284151]\n",
      "  [-0.01287368 -0.0047118 ]\n",
      "  [-0.00080796 -0.0057631 ]\n",
      "  [-0.00047308 -0.00605654]\n",
      "  [-0.00331537  0.00746535]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, max_length])\n",
    "\n",
    "# Embedding\n",
    "top_words = 6 # 0 ~ 5\n",
    "embedding_length = 3\n",
    "embedding = Embedding(input_dim=top_words, output_dim=embedding_length, input_length=max_length)(X)\n",
    "\n",
    "# LSTM\n",
    "outputs = LSTM(2, return_sequences=True)(embedding)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = sess.run(outputs, feed_dict={X: pad_texts})\n",
    "    print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
